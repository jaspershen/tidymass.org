---
title: "Tune model parameters"
weight: 4
tags: [rsample, parsnip, tune, dials, workflows, yardstick]
categories: [tuning]
description: | 
  Estimate the best values for hyperparameters that cannot be learned directly during model training.
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
source(here::here("content/start/common.R"))
```

```{r load, include = FALSE, message = FALSE, warning = FALSE}
library(tidymodels)
library(rpart)
library(rpart.plot)
library(kableExtra)
library(vip)
theme_set(theme_bw())
doParallel::registerDoParallel()
pkgs <- c("tidymodels", "rpart", "rpart.plot", "vip")
```


## Introduction {#intro}

Some model parameters cannot be learned directly from a data set during model training; these kinds of parameters are called **hyperparameters**. Some examples of hyperparameters include the number of predictors that are sampled at splits in a tree-based model (we call this `mtry` in tidymodels) or the learning rate in a boosted tree model (we call this `learn_rate`). Instead of learning these kinds of hyperparameters during model training, we can _estimate_ the best values for these values by training many models on resampled data sets and exploring how well all these models perform. This process is called **tuning**.

## Session information

```{r si, echo = FALSE}
small_session(pkgs)
```
